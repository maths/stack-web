# Example generation and educational research

### George Kinnear, The University of Edinburgh, UK

<center>
<iframe class="embed-responsive-item" width="560" height="315" src="https://www.youtube.com/embed/Q_m-j5rZF6o" frameborder="0" allow="accelerometer; autoplay; encrypted-media; gyroscope; picture-in-picture" allowfullscreen></iframe>
</center>

Example-generation tasks ask students to produce examples of mathematical objects.  Many mathematics education researchers are interested in how students approach this type of task, and how they can help students to learn about mathematical concepts (Kinnear et al., 2022).
E-assessment tools like STACK enable teachers to use example-generation tasks even with very large classes of students, so that each students get personal feedback.

Thanks to the AuthOMath project, GeoGebra applets can now be used as a way for students to input a *graphical answer* to a STACK question.
This opens up a wide range of topics where teachers are now able to set example-generation tasks.

For example, this question is taken from a first-year course at the University of Edinburgh, where students are learning about the properties of functions:
<div class="float-none img-middle">
<figure class="figure">
<img class="figure-img img-fluid" src="../Images/gk-example-task-screenshot1.png" alt="A correct response">
<figcaption class="figure-caption">Figure: A question asking students to construct the graph of a function.</figcaption>
</figure></div>

To answer the question, the student can drag the four points and draw the graph of a piecewise linear function with the required properties. Behind the scenes, STACK can check the properties of the student's graph.

If there are any errors, the student can be given customised feedback that refers to their particular answer:
<div class="float-none img-middle">
<figure class="figure">
<img class="figure-img img-fluid" src="../Images/gk-example-task-screenshot2.png" alt="An incorrect response">
<figcaption class="figure-caption">Figure: An incorrect response together with the automatically-generated feedback.</figcaption>
</figure></div>

For this example, it turns out that students found the e-assessment task harder than the same one on paper (Kinnear et al., 2023). This was likely because the applet constrained students to using examples that are piecewise-linear functions, which are not the most familiar examples for students.

There is great potential for further work to develop tasks (and sequences of tasks) like this, making full use of the power of GeoGebra so that students can produce graphical examples.


## References

Kinnear, G., Jones, I., Sangwin, C., Alarfaj, M., Davies, B., Fearn, S., Foster, C., Heck, A., Henderson, K., Hunt, T., Iannone, P., Kontorovich, I., Larson, N., Lowe, T., Meyer, J. C., O’Shea, A., Rowlett, P., Sikurajapathi, I., & Wong, T. (2022). A Collaboratively-Derived Research Agenda for E-assessment in Undergraduate Mathematics. International Journal of Research in Undergraduate Mathematics Education. [https://doi.org/10.1007/s40753-022-00189-6](https://doi.org/10.1007/s40753-022-00189-6)

Kinnear, G., Iannone, P., & Davies, B. (2023). Insights about functions from example-generation tasks: combining e-assessment and written responses. In P. Drijvers, C. Csapodi, H. Palmér, K. Gosztonyi, & E. Kónya (Eds.), Proceedings of the Thirteenth Congress of the European Society for Research in Mathematics Education (CERME13) (pp. 2399–2406). Alfréd Rényi Institute of Mathematics and ERME.
